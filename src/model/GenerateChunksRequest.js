/**
 * Trieve API
 * Trieve OpenAPI Specification. This document describes all of the operations available through the Trieve API.
 *
 * The version of the OpenAPI document: 0.5.0
 * Contact: developers@trieve.ai
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';
import ChatMessageProxy from './ChatMessageProxy';

/**
 * The GenerateChunksRequest model module.
 * @module model/GenerateChunksRequest
 * @version 0.5.0
 */
class GenerateChunksRequest {
    /**
     * Constructs a new <code>GenerateChunksRequest</code>.
     * @alias module:model/GenerateChunksRequest
     * @param chunkIds {Array.<String>} The ids of the chunks to be retrieved and injected into the context window for RAG.
     * @param prevMessages {Array.<module:model/ChatMessageProxy>} The previous messages to be placed into the chat history. The last message in this array will be the prompt for the model to inference on. The length of this array must be at least 1.
     */
    constructor(chunkIds, prevMessages) { 
        
        GenerateChunksRequest.initialize(this, chunkIds, prevMessages);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj, chunkIds, prevMessages) { 
        obj['chunk_ids'] = chunkIds;
        obj['prev_messages'] = prevMessages;
    }

    /**
     * Constructs a <code>GenerateChunksRequest</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/GenerateChunksRequest} obj Optional instance to populate.
     * @return {module:model/GenerateChunksRequest} The populated <code>GenerateChunksRequest</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new GenerateChunksRequest();

            if (data.hasOwnProperty('chunk_ids')) {
                obj['chunk_ids'] = ApiClient.convertToType(data['chunk_ids'], ['String']);
            }
            if (data.hasOwnProperty('model')) {
                obj['model'] = ApiClient.convertToType(data['model'], 'String');
            }
            if (data.hasOwnProperty('prev_messages')) {
                obj['prev_messages'] = ApiClient.convertToType(data['prev_messages'], [ChatMessageProxy]);
            }
            if (data.hasOwnProperty('prompt')) {
                obj['prompt'] = ApiClient.convertToType(data['prompt'], 'String');
            }
            if (data.hasOwnProperty('stream_response')) {
                obj['stream_response'] = ApiClient.convertToType(data['stream_response'], 'Boolean');
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>GenerateChunksRequest</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>GenerateChunksRequest</code>.
     */
    static validateJSON(data) {
        // check to make sure all required properties are present in the JSON string
        for (const property of GenerateChunksRequest.RequiredProperties) {
            if (!data.hasOwnProperty(property)) {
                throw new Error("The required field `" + property + "` is not found in the JSON data: " + JSON.stringify(data));
            }
        }
        // ensure the json data is an array
        if (!Array.isArray(data['chunk_ids'])) {
            throw new Error("Expected the field `chunk_ids` to be an array in the JSON data but got " + data['chunk_ids']);
        }
        // ensure the json data is a string
        if (data['model'] && !(typeof data['model'] === 'string' || data['model'] instanceof String)) {
            throw new Error("Expected the field `model` to be a primitive type in the JSON string but got " + data['model']);
        }
        if (data['prev_messages']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['prev_messages'])) {
                throw new Error("Expected the field `prev_messages` to be an array in the JSON data but got " + data['prev_messages']);
            }
            // validate the optional field `prev_messages` (array)
            for (const item of data['prev_messages']) {
                ChatMessageProxy.validateJSON(item);
            };
        }
        // ensure the json data is a string
        if (data['prompt'] && !(typeof data['prompt'] === 'string' || data['prompt'] instanceof String)) {
            throw new Error("Expected the field `prompt` to be a primitive type in the JSON string but got " + data['prompt']);
        }

        return true;
    }


}

GenerateChunksRequest.RequiredProperties = ["chunk_ids", "prev_messages"];

/**
 * The ids of the chunks to be retrieved and injected into the context window for RAG.
 * @member {Array.<String>} chunk_ids
 */
GenerateChunksRequest.prototype['chunk_ids'] = undefined;

/**
 * The model to use for the chat. This can be any model from the openrouter model list. If no model is provided, gpt-3.5-turbo will be used.
 * @member {String} model
 */
GenerateChunksRequest.prototype['model'] = undefined;

/**
 * The previous messages to be placed into the chat history. The last message in this array will be the prompt for the model to inference on. The length of this array must be at least 1.
 * @member {Array.<module:model/ChatMessageProxy>} prev_messages
 */
GenerateChunksRequest.prototype['prev_messages'] = undefined;

/**
 * Prompt for the last message in the prev_messages array. This will be used to generate the next message in the chat. The default is 'Respond to the instruction and include the doc numbers that you used in square brackets at the end of the sentences that you used the docs for:'. You can also specify an empty string to leave the final message alone such that your user's final message can be used as the prompt. See docs.trieve.ai or contact us for more information.
 * @member {String} prompt
 */
GenerateChunksRequest.prototype['prompt'] = undefined;

/**
 * Whether or not to stream the response. If this is set to true or not included, the response will be a stream. If this is set to false, the response will be a normal JSON response. Default is true.
 * @member {Boolean} stream_response
 */
GenerateChunksRequest.prototype['stream_response'] = undefined;






export default GenerateChunksRequest;

